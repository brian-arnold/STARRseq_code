{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pyranges as pr\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(\"/Genomics/kocherlab/bjarnold/STARRseq/code/notebooks\")\n",
    "import functions as fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Genomics/kocherlab/bjarnold/STARRseq/data/MACS2_bdg_output\"\n",
    "biorep = \"F3\"\n",
    "\n",
    "statistic = \"treat_pileup\" # \"treat_pileup\", or \"control_lambda\"\n",
    "\n",
    "orig_file = f\"{base_dir}/Amel-{biorep}_{statistic}.bdg\"\n",
    "dwnsamp_file = f\"{base_dir}/Amel_prop0.1-{biorep}_{statistic}.bdg\"\n",
    "\n",
    "orig_df = pd.read_csv(orig_file, sep=\"\\t\", header=None)\n",
    "orig_df.columns = [\"chr\", \"start\", \"end\", statistic]\n",
    "orig_df['interval_length'] = orig_df['end'] - orig_df['start']  \n",
    "\n",
    "dwnsamp_df = pd.read_csv(dwnsamp_file, sep=\"\\t\", header=None)\n",
    "dwnsamp_df.columns = [\"chr\", \"start\", \"end\", statistic]\n",
    "dwnsamp_df['interval_length'] = dwnsamp_df['end'] - dwnsamp_df['start']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute weighted average of control_lambda column, weighted by interval length\n",
    "# orig_weighted_avg = np.average(orig_df[statistic], weights=orig_df['interval_length'])\n",
    "# dwnsamp_weighted_avg = np.average(dwnsamp_df[statistic], weights=dwnsamp_df['interval_length'])\n",
    "\n",
    "# # compute weighted standard deviation of control_lambda column, weighted by interval length\n",
    "# orig_weighted_std = np.sqrt(np.average((orig_df[statistic] - orig_weighted_avg)**2, weights=orig_df['interval_length']))\n",
    "# dwnsamp_weighted_std = np.sqrt(np.average((dwnsamp_df[statistic] - dwnsamp_weighted_avg)**2, weights=dwnsamp_df['interval_length']))\n",
    "\n",
    "# orif_coeff_var = orig_weighted_std/orig_weighted_avg\n",
    "# dwnsamp_coeff_var = dwnsamp_weighted_std/dwnsamp_weighted_avg\n",
    "\n",
    "# print(orig_weighted_avg, orig_weighted_std, orif_coeff_var)\n",
    "# print(dwnsamp_weighted_avg, dwnsamp_weighted_std, dwnsamp_coeff_var)\n",
    "\n",
    "# print(dwnsamp_coeff_var/orif_coeff_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47058823529411764\n",
      "0.4782608695652174\n"
     ]
    }
   ],
   "source": [
    "# calculate the Quartile coefficient of dispersion\n",
    "orig_q1 = orig_df[statistic].quantile(0.25)\n",
    "orig_q3 = orig_df[statistic].quantile(0.75)\n",
    "orig_iqr = orig_q3 - orig_q1\n",
    "orig_qcod = orig_iqr/(orig_q3 + orig_q1)\n",
    "\n",
    "dwnsamp_q1 = dwnsamp_df[statistic].quantile(0.25)\n",
    "dwnsamp_q3 = dwnsamp_df[statistic].quantile(0.75)\n",
    "dwnsamp_iqr = dwnsamp_q3 - dwnsamp_q1\n",
    "dwnsamp_qcod = dwnsamp_iqr/(dwnsamp_q3 + dwnsamp_q1)\n",
    "\n",
    "print(orig_qcod)\n",
    "print(dwnsamp_qcod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
